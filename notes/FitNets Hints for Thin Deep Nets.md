#deep-learning #CIFAR

![[Pasted image 20250531091325.png]]
- motivation
	- key to deep learning is network depth
		- but the high amount of layers also makes training hard due to more non-linearity
	- is there a better way
- introduced method: *FitNets*
	- idea: use knowledge distillation to imitate already trained deep networks
	- by making them thinner, they can also be deeper and thus more expressive

ğŸ—“ï¸ 2015

âœï¸
- [[Adriana Romero]]
- [[Nicolas Ballas]]
- [[Samira Ebrahimi Kahou]]
- [[Antoine Chassang]]
- [[Carlo Gatta]]
- [[Yoshua Bengio]]
